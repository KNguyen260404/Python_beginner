import re
import string
import json
import os
from collections import Counter
from typing import Dict, List, Tuple

class TextAnalyzer:
    def __init__(self):
        self.text = ""
        self.words = []
        self.sentences = []
        self.paragraphs = []
        self.word_count = 0
        self.sentence_count = 0
        self.paragraph_count = 0
        self.char_count = 0
        self.history_file = "text_analysis_history.json"
        self.history = self.load_history()
        
    def load_history(self) -> List[Dict]:
        """Load analysis history from file"""
        if os.path.exists(self.history_file):
            try:
                with open(self.history_file, "r", encoding="utf-8") as file:
                    return json.load(file)
            except json.JSONDecodeError:
                return []
        return []
    
    def save_history(self, title: str, summary: Dict):
        """Save analysis to history"""
        self.history.append({
            "title": title,
            "summary": summary
        })
        
        # Keep only last 10 analyses
        if len(self.history) > 10:
            self.history = self.history[-10:]
            
        with open(self.history_file, "w", encoding="utf-8") as file:
            json.dump(self.history, file, indent=4)
    
    def load_text(self, text: str):
        """Load text for analysis"""
        self.text = text
        
        # Split into paragraphs
        self.paragraphs = [p for p in text.split("\n\n") if p.strip()]
        self.paragraph_count = len(self.paragraphs)
        
        # Split into sentences
        self.sentences = re.split(r'[.!?]+', text)
        self.sentences = [s.strip() for s in self.sentences if s.strip()]
        self.sentence_count = len(self.sentences)
        
        # Split into words
        self.words = re.findall(r'\b[a-zA-Z0-9_\u00C0-\u1EF9]+\b', text.lower())
        self.word_count = len(self.words)
        
        # Count characters
        self.char_count = len(text)
    
    def load_from_file(self, file_path: str):
        """Load text from file"""
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                self.load_text(file.read())
            return True
        except Exception as e:
            print(f"Lá»—i khi Ä‘á»c file: {e}")
            return False
    
    def get_word_frequency(self, limit: int = 10) -> List[Tuple[str, int]]:
        """Get word frequency"""
        # Remove common stop words
        stop_words = {"vÃ ", "lÃ ", "cá»§a", "cÃ³", "trong", "cho", "khÃ´ng", "vá»›i", "nÃ y", "Ä‘Ã³", "cÃ¡c", "nhá»¯ng"}
        filtered_words = [word for word in self.words if word not in stop_words and len(word) > 1]
        
        # Count word frequency
        word_counts = Counter(filtered_words)
        return word_counts.most_common(limit)
    
    def calculate_readability(self) -> Dict:
        """Calculate readability metrics"""
        if not self.words or not self.sentences:
            return {
                "flesch_reading_ease": 0,
                "difficulty": "N/A"
            }
        
        # Average words per sentence
        avg_words_per_sentence = self.word_count / max(1, self.sentence_count)
        
        # Average syllables per word (rough estimation for Vietnamese)
        syllable_count = 0
        for word in self.words:
            # Simple estimation: count vowel groups
            vowels = "aeiouyÃ Ã¡Ã¢Ã£Ã¨Ã©ÃªÃ¬Ã­Ã²Ã³Ã´ÃµÃ¹ÃºÃ½ÄƒÃ¢ÃªÃ´Æ¡Æ°Æ°á»Ÿá»£á»™áº¿á»á»ƒá»…á»‘á»“á»•á»—á»›á»á»Ÿá»£á»¥á»§á»©á»«á»­á»¯"
            syllable_count += len(re.findall(r'[' + vowels + ']+', word))
        
        avg_syllables_per_word = syllable_count / max(1, self.word_count)
        
        # Flesch Reading Ease (adapted)
        # Higher score = easier to read (0-100)
        flesch = 206.835 - (1.015 * avg_words_per_sentence) - (84.6 * avg_syllables_per_word)
        flesch = max(0, min(100, flesch))
        
        # Determine difficulty
        if flesch >= 90:
            difficulty = "Ráº¥t dá»… Ä‘á»c"
        elif flesch >= 80:
            difficulty = "Dá»… Ä‘á»c"
        elif flesch >= 70:
            difficulty = "KhÃ¡ dá»… Ä‘á»c"
        elif flesch >= 60:
            difficulty = "Trung bÃ¬nh"
        elif flesch >= 50:
            difficulty = "KhÃ¡ khÃ³ Ä‘á»c"
        elif flesch >= 30:
            difficulty = "KhÃ³ Ä‘á»c"
        else:
            difficulty = "Ráº¥t khÃ³ Ä‘á»c"
            
        return {
            "flesch_reading_ease": round(flesch, 2),
            "avg_words_per_sentence": round(avg_words_per_sentence, 2),
            "avg_syllables_per_word": round(avg_syllables_per_word, 2),
            "difficulty": difficulty
        }
    
    def estimate_sentiment(self) -> Dict:
        """Estimate text sentiment (very simple approach)"""
        # Simple sentiment dictionary (would be expanded in real application)
        positive_words = {"tá»‘t", "hay", "tuyá»‡t", "vui", "thÃ­ch", "yÃªu", "thÃ nh cÃ´ng", "háº¡nh phÃºc", 
                         "xinh", "Ä‘áº¹p", "giá»i", "thÃ´ng minh", "tuyá»‡t vá»i", "xuáº¥t sáº¯c"}
        negative_words = {"tá»‡", "buá»“n", "ghÃ©t", "tháº¥t báº¡i", "kÃ©m", "xáº¥u", "khÃ³", "sai", 
                         "chÃ¡n", "tá»“i", "dá»Ÿ", "há»ng", "Ä‘Ã¡ng sá»£", "kinh khá»§ng"}
        
        positive_count = sum(1 for word in self.words if word in positive_words)
        negative_count = sum(1 for word in self.words if word in negative_words)
        
        # Calculate sentiment score (-1 to 1)
        total = positive_count + negative_count
        if total == 0:
            sentiment_score = 0
        else:
            sentiment_score = (positive_count - negative_count) / total
            
        # Determine sentiment category
        if sentiment_score >= 0.5:
            sentiment = "TÃ­ch cá»±c"
        elif sentiment_score >= 0.1:
            sentiment = "HÆ¡i tÃ­ch cá»±c"
        elif sentiment_score > -0.1:
            sentiment = "Trung láº­p"
        elif sentiment_score > -0.5:
            sentiment = "HÆ¡i tiÃªu cá»±c"
        else:
            sentiment = "TiÃªu cá»±c"
            
        return {
            "sentiment_score": round(sentiment_score, 2),
            "sentiment": sentiment,
            "positive_words": positive_count,
            "negative_words": negative_count
        }
    
    def analyze(self, title: str = "Untitled") -> Dict:
        """Perform full text analysis"""
        if not self.text:
            return {"error": "KhÃ´ng cÃ³ vÄƒn báº£n Ä‘á»ƒ phÃ¢n tÃ­ch"}
            
        # Basic statistics
        basic_stats = {
            "word_count": self.word_count,
            "sentence_count": self.sentence_count,
            "paragraph_count": self.paragraph_count,
            "character_count": self.char_count
        }
        
        # Word frequency
        word_freq = self.get_word_frequency(10)
        
        # Readability
        readability = self.calculate_readability()
        
        # Sentiment
        sentiment = self.estimate_sentiment()
        
        # Compile results
        results = {
            "title": title,
            "basic_stats": basic_stats,
            "word_frequency": dict(word_freq),
            "readability": readability,
            "sentiment": sentiment
        }
        
        # Save to history
        self.save_history(title, results)
        
        return results
    
    def display_results(self, results: Dict):
        """Display analysis results"""
        print("\n" + "=" * 50)
        print(f"ğŸ“Š Káº¾T QUáº¢ PHÃ‚N TÃCH VÄ‚N Báº¢N: {results['title']}")
        print("=" * 50)
        
        # Basic stats
        stats = results["basic_stats"]
        print("\nğŸ“ THá»NG KÃŠ CÆ  Báº¢N:")
        print(f"ğŸ“Š Sá»‘ tá»«: {stats['word_count']}")
        print(f"ğŸ“Š Sá»‘ cÃ¢u: {stats['sentence_count']}")
        print(f"ğŸ“Š Sá»‘ Ä‘oáº¡n: {stats['paragraph_count']}")
        print(f"ğŸ“Š Sá»‘ kÃ½ tá»±: {stats['character_count']}")
        
        # Word frequency
        print("\nğŸ“ˆ Táº¦N SUáº¤T Tá»ª (TOP 10):")
        for word, count in results["word_frequency"].items():
            print(f"   {word}: {count}")
        
        # Readability
        read = results["readability"]
        print("\nğŸ“– Äá»˜ KHÃ“ VÄ‚N Báº¢N:")
        print(f"ğŸ“Š Äiá»ƒm Ä‘á»c Flesch: {read['flesch_reading_ease']}")
        print(f"ğŸ“Š Äá»™ khÃ³: {read['difficulty']}")
        print(f"ğŸ“Š Trung bÃ¬nh tá»«/cÃ¢u: {read.get('avg_words_per_sentence', 'N/A')}")
        print(f"ğŸ“Š Trung bÃ¬nh Ã¢m tiáº¿t/tá»«: {read.get('avg_syllables_per_word', 'N/A')}")
        
        # Sentiment
        sent = results["sentiment"]
        print("\nğŸ˜Š PHÃ‚N TÃCH Cáº¢M XÃšC:")
        print(f"ğŸ“Š Äiá»ƒm cáº£m xÃºc: {sent['sentiment_score']}")
        print(f"ğŸ“Š ÄÃ¡nh giÃ¡: {sent['sentiment']}")
        print(f"ğŸ“Š Tá»« tÃ­ch cá»±c: {sent['positive_words']}")
        print(f"ğŸ“Š Tá»« tiÃªu cá»±c: {sent['negative_words']}")
        
        print("\n" + "=" * 50)
    
    def show_history(self):
        """Display analysis history"""
        if not self.history:
            print("ChÆ°a cÃ³ lá»‹ch sá»­ phÃ¢n tÃ­ch nÃ o!")
            return
            
        print("\n=== Lá»ŠCH Sá»¬ PHÃ‚N TÃCH ===")
        for i, entry in enumerate(self.history, 1):
            stats = entry["summary"]["basic_stats"]
            sentiment = entry["summary"]["sentiment"]["sentiment"]
            print(f"{i}. {entry['title']} - {stats['word_count']} tá»« - Cáº£m xÃºc: {sentiment}")
    
    def run_cli(self):
        """Run the text analyzer CLI"""
        print("\nğŸ” PHÃ‚N TÃCH VÄ‚N Báº¢N ğŸ“Š")
        print("CÃ´ng cá»¥ phÃ¢n tÃ­ch vÄƒn báº£n tiáº¿ng Viá»‡t")
        
        while True:
            print("\n" + "=" * 50)
            print("1. Nháº­p vÄƒn báº£n trá»±c tiáº¿p")
            print("2. Äá»c vÄƒn báº£n tá»« file")
            print("3. Xem lá»‹ch sá»­ phÃ¢n tÃ­ch")
            print("4. ThoÃ¡t")
            
            choice = input("\nChá»n má»™t tÃ¹y chá»n (1-4): ")
            
            if choice == "1":
                print("\nNháº­p vÄƒn báº£n cá»§a báº¡n (nháº¥n Enter hai láº§n Ä‘á»ƒ káº¿t thÃºc):")
                lines = []
                while True:
                    line = input()
                    if not line and lines and not lines[-1]:
                        break
                    lines.append(line)
                
                text = "\n".join(lines)
                if text.strip():
                    title = input("Nháº­p tiÃªu Ä‘á» cho phÃ¢n tÃ­ch nÃ y: ")
                    self.load_text(text)
                    results = self.analyze(title)
                    self.display_results(results)
                else:
                    print("VÄƒn báº£n trá»‘ng!")
                    
            elif choice == "2":
                file_path = input("Nháº­p Ä‘Æ°á»ng dáº«n Ä‘áº¿n file vÄƒn báº£n: ")
                if self.load_from_file(file_path):
                    title = input("Nháº­p tiÃªu Ä‘á» cho phÃ¢n tÃ­ch nÃ y: ")
                    results = self.analyze(title)
                    self.display_results(results)
                    
            elif choice == "3":
                self.show_history()
                
                if self.history:
                    view_details = input("\nXem chi tiáº¿t phÃ¢n tÃ­ch? Nháº­p sá»‘ thá»© tá»± (hoáº·c 0 Ä‘á»ƒ quay láº¡i): ")
                    try:
                        idx = int(view_details) - 1
                        if 0 <= idx < len(self.history):
                            self.display_results(self.history[idx]["summary"])
                    except ValueError:
                        pass
                    
            elif choice == "4":
                print("Cáº£m Æ¡n báº¡n Ä‘Ã£ sá»­ dá»¥ng cÃ´ng cá»¥ phÃ¢n tÃ­ch vÄƒn báº£n!")
                break
                
            else:
                print("Lá»±a chá»n khÃ´ng há»£p lá»‡!")

if __name__ == "__main__":
    analyzer = TextAnalyzer()
    analyzer.run_cli() 